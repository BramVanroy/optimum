{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-classification\n",
    "\n",
    "[REF](https://github.com/pytorch/ort/blob/3c14f36cdacb15ed0de7ba8559e827e5004c7b1f/torch_ort_inference/torch_ort/ortinferencemodule/ortinferencemodule.py#L109)\n",
    "```python\n",
    "self._device = _utils_infer.get_device_from_module(module)\n",
    "\n",
    "\n",
    "run_options = C.RunOptions()\n",
    "\n",
    "# Pre-process inputs to make them compatible with onnxruntime\n",
    "onnx_input_names = [inp.name for inp in self._onnx_models.exported_model.graph.input]\n",
    "inputs = _utils_infer.get_user_inputs(onnx_input_names, self._flattened_module._input_info, inputs, kwargs, self._device)\n",
    "\n",
    "io_binding = self._inference_session.io_binding()\n",
    "_utils._create_iobinding(io_binding, inputs, self._onnx_models.exported_model, self._device)\n",
    "\n",
    "# Run inference session\n",
    "self._inference_session.run_with_iobinding(io_binding, run_options)\n",
    "\n",
    "# Post-process outputs to make them compatible with pytorch\n",
    "forward_outputs = io_binding._iobinding.get_outputs()\n",
    "\n",
    "user_outputs = _utils._ortvalues_to_torch_tensor(forward_outputs, self._device)\n",
    "return _io.unflatten_user_output(self._module_output_schema, user_outputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new utils\n",
    "\n",
    "_need onnxruntime-training_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnxruntime onnxruntime-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from onnxruntime.capi.onnxruntime_inference_collection import OrtValue\n",
    "from distutils.version import LooseVersion\n",
    "from torch.utils.dlpack import to_dlpack\n",
    "from onnxruntime.capi import _pybind_state as C # needs onnxruntime-training \n",
    "from torch._C import _from_dlpack\n",
    "\n",
    "def _ortvalue_from_torch_tensor(torch_tensor):\n",
    "    # TODO: Current DLPack doesn't support bool and PyTorch disables converting bool tensor to DLPack in recent commit.\n",
    "    # https://github.com/pytorch/pytorch/blob/7e7be526c9d9179f35084e9cca5b5c5ad5172100/aten/src/ATen/DLConvertor.cpp#L41\n",
    "    # We need to convert bool tensor to unit8 tensor to workaround this.\n",
    "    # DLPack is discussing how to support bool type, we can remove this workaround once both DLPack\n",
    "    # and PyTorch support bool type.\n",
    "    is_bool_tensor = torch_tensor.dtype == torch.bool\n",
    "    if is_bool_tensor and LooseVersion(torch.__version__) >= LooseVersion(\"1.10.0\"):\n",
    "        torch_tensor = torch_tensor.to(torch.uint8)\n",
    "    # print(torch_tensor.device)\n",
    "    if torch_tensor.device.type == \"ort\":\n",
    "        return C.aten_ort_tensor_to_ort_value(torch_tensor)\n",
    "    return C.OrtValue.from_dlpack(to_dlpack(torch_tensor), is_bool_tensor)\n",
    "\n",
    "def _ortvalues_to_torch_tensor(ortvalues, device):\n",
    "    if len(ortvalues) == 0:\n",
    "        return []\n",
    "\n",
    "    if \"ort\" == device.type:\n",
    "        if not hasattr(C, \"to_aten_ort_device_tensor\"):\n",
    "            raise AttributeError(\"onnxruntime is missing to_aten_ort_device_tensor needed to support device == 'ort'.\")\n",
    "        return [C.to_aten_ort_device_tensor(ov) for ov in ortvalues]\n",
    "\n",
    "    if not isinstance(ortvalues, C.OrtValueVector):\n",
    "        raise TypeError(\"ortvalues must be an instance of OrtValueVector not %r.\" % type(ortvalues))\n",
    "\n",
    "    res = ortvalues.to_dlpacks(_from_dlpack)\n",
    "    bool_indices = ortvalues.bool_tensor_indices()\n",
    "    if len(bool_indices):\n",
    "        # DLPack structure does not know for sure if it stores boolean\n",
    "        # or uint8. Method to_dlpacks cannot be used in that case.\n",
    "        # Signature of *dl_packs* is `to_dlpacks(dlp, fct) -> list[torch.Tensor]`.\n",
    "        # And fct is a function with signature `fct(dlp) -> torch.Tensor`.\n",
    "        # Boolean tensors are converted into uint8 tensor with the DLPack protocol.\n",
    "        # Therefore, the function `fct` does not know if the dlpack structure\n",
    "        # is a boolean tensor or a uint8 tensor.\n",
    "        # We could either consider another function as an input in\n",
    "        # `to_dlpacks` or add an argument to `fct(dlp, ortvalue)`.\n",
    "        # Second option makes it impossible to directly use `_from_dlpack` or\n",
    "        # or `from_dlpack` from torch.\n",
    "        # The best option would be to add boolean type in DLDataTypeCode.\n",
    "        for i in range(0, len(bool_indices)):\n",
    "            j = bool_indices[i]\n",
    "            res[j] = res[j].to(torch.bool)\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_device_index(device):\n",
    "    if isinstance(device, str):\n",
    "        # could be 'cuda:0', 'cuda:1', or 'cpu'. with cpu, set index=0\n",
    "        device = torch.device(device)\n",
    "    elif isinstance(device, int):\n",
    "        return device\n",
    "    return 0 if device.index is None else device.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manual test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92489685cc75417b9b7e8ad378f57fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/710 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6277741e6b4c39afe72ccaf679b310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[ 3.8724, -3.1543]])]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model = ORTModelForSequenceClassification.from_pretrained(\"optimum/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"optimum/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "payload = \"I hate you\"\n",
    "\n",
    "d = tokenizer(payload, return_tensors=\"pt\")\n",
    "\n",
    "io_binding = model.model.io_binding()\n",
    "# inputs\n",
    "for key,val in d.items():\n",
    "  io_binding.bind_ortvalue_input(key, OrtValue(_ortvalue_from_torch_tensor(val)))\n",
    "# outputs\n",
    "for name in list(model.model_outputs.keys()):\n",
    "    io_binding.bind_output(name, model.device.type, device_id=get_device_index(model.device))\n",
    "model.model.run_with_iobinding(io_binding)\n",
    "# Copy output contents to CPU (if on another device). No-op if already on the CPU.\n",
    "# Y = io_binding.copy_outputs_to_cpu()[0]\n",
    "raw_outputs= io_binding._iobinding.get_outputs()\n",
    "outputs = _ortvalues_to_torch_tensor(raw_outputs, model.device)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-3.7966,  4.0482]])]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = \"I hate you. I hate you. But i like you\"\n",
    "\n",
    "d = tokenizer(payload, return_tensors=\"pt\")\n",
    "\n",
    "io_binding = model.model.io_binding()\n",
    "# inputs\n",
    "for key,val in d.items():\n",
    "  io_binding.bind_ortvalue_input(key, OrtValue(_ortvalue_from_torch_tensor(val)))\n",
    "# outputs\n",
    "for name in list(model.model_outputs.keys()):\n",
    "    io_binding.bind_output(name, model.device.type, device_id=get_device_index(model.device))\n",
    "model.model.run_with_iobinding(io_binding)\n",
    "# Copy output contents to CPU (if on another device). No-op if already on the CPU.\n",
    "# Y = io_binding.copy_outputs_to_cpu()[0]\n",
    "raw_outputs= io_binding._iobinding.get_outputs()\n",
    "outputs = _ortvalues_to_torch_tensor(raw_outputs, model.device)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "from transformers.modeling_outputs import (\n",
    "    SequenceClassifierOutput,\n",
    ")\n",
    "\n",
    "class IOBindingModel(ORTModelForSequenceClassification):\n",
    "  def __init__(self, model=None, config=None, **kwargs):\n",
    "    super().__init__(model, config, **kwargs)\n",
    "    # create {name:idx} dict for model outputs\n",
    "    self.model_outputs = {output_key.name: idx for idx, output_key in enumerate(self.model.get_outputs())}\n",
    "    self.model_inputs = {output_key.name: idx for idx, output_key in enumerate(self.model.get_inputs())}\n",
    "    self.model_input_names = list(self.model_inputs.keys())\n",
    "    self.model_output_names = list(self.model_outputs.keys())\n",
    "    self.run_options = C.RunOptions()\n",
    "    \n",
    "  def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.io_binding = self.model.io_binding()\n",
    "\n",
    "        # add input io binding\n",
    "        self.io_binding.bind_ortvalue_input(\"input_ids\", OrtValue(_ortvalue_from_torch_tensor(input_ids)))\n",
    "        self.io_binding.bind_ortvalue_input(\"attention_mask\", OrtValue(_ortvalue_from_torch_tensor(attention_mask)))\n",
    "        if token_type_ids is not None:\n",
    "          self.io_binding.bind_ortvalue_input(\"token_type_ids\", OrtValue(_ortvalue_from_torch_tensor(token_type_ids)))\n",
    "\n",
    "        # add output io binding\n",
    "        for name in list(model.model_outputs.keys()):\n",
    "          self.io_binding.bind_output(name, self.device.type, device_id=get_device_index(self.device))\n",
    "        \n",
    "        # run inference with binding\n",
    "        model.model.run_with_iobinding(self.io_binding,self.run_options)\n",
    "        # Copy output contents to CPU (if on another device). No-op if already on the CPU.\n",
    "        # Y = io_binding.copy_outputs_to_cpu()[0]\n",
    "        raw_outputs= self.io_binding._iobinding.get_outputs()\n",
    "        outputs = _ortvalues_to_torch_tensor(raw_outputs, model.device)        \n",
    "        return SequenceClassifierOutput(logits=outputs[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab970c817a542e2b8a00d0ebc4ee7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/710 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a54b50f8374261b18a196caceea842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1045, 5223, 2017,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model = ORTModelForSequenceClassification.from_pretrained(\"optimum/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"optimum/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "payload = \"I hate you\"\n",
    "\n",
    "d = tokenizer(payload, return_tensors=\"pt\")\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011d0ad61bc74dd5be08e630c2468191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/710 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae328cc2ec4145b2ab16c7e59c7d5701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "io_model = IOBindingModel.from_pretrained(\"optimum/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "io_model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1045, 5223, 2017, 1012,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# payload = \"I hate you.\"\n",
    "palyoad = \"I love you so much. It is incredible what a good person you are. I love you so much. It is incredible what a good person you are.\"\n",
    "\n",
    "d = tokenizer(payload, return_tensors=\"pt\")\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.2 ms ± 153 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit io_model(**d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.4 ms ± 2.34 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model(**d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.9981, -3.2588]])\n",
      "tensor([[ 3.9981, -3.2588]])\n"
     ]
    }
   ],
   "source": [
    "io = io_model(**d)\n",
    "van = model(**d)\n",
    "print(io.logits)\n",
    "print(van.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "import numpy as np\n",
    "\n",
    "def benchmark(seq_len,model,tokenizer):\n",
    "    # prepare date\n",
    "    seq_len = \"l \" * (seq_len - 2)\n",
    "    payload = tokenizer(seq_len, return_tensors=\"pt\")\n",
    "    latencies = []\n",
    "    # warm up\n",
    "    for _ in range(10):\n",
    "        _ = model(**payload)\n",
    "    # Timed run\n",
    "    for _ in range(100):\n",
    "        start_time = perf_counter()\n",
    "        _ =  model(**payload)\n",
    "        latency = perf_counter() - start_time\n",
    "        latencies.append(latency)\n",
    "    # Compute run statistics\n",
    "    time_avg_ms = 1000 * np.mean(latencies)\n",
    "    time_p95_ms = 1000 * np.percentile(latencies,95)\n",
    "    return {\"seq_len\":payload[\"input_ids\"].shape[1],\"time_avg_ms\":time_avg_ms,\"time_p95_ms\":time_p95_ms}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "seq_lengths=[8,16,32,64,128,256,512]\n",
    "res =[]\n",
    "for seq_len in seq_lengths:\n",
    "    io = benchmark(seq_len,io_model,tokenizer)\n",
    "    res.append({**io,\"model\":\"io\"})\n",
    "    \n",
    "    vanilla = benchmark(seq_len,model,tokenizer)\n",
    "    res.append({**vanilla,\"model\":\"vanilla\"})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_len</th>\n",
       "      <th>model</th>\n",
       "      <th>time_avg_ms</th>\n",
       "      <th>time_p95_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>io</td>\n",
       "      <td>21.845188</td>\n",
       "      <td>31.285430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>vanilla</td>\n",
       "      <td>19.478945</td>\n",
       "      <td>25.687145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>io</td>\n",
       "      <td>21.550402</td>\n",
       "      <td>22.859014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>vanilla</td>\n",
       "      <td>21.397938</td>\n",
       "      <td>21.801143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>io</td>\n",
       "      <td>27.146151</td>\n",
       "      <td>28.067425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>vanilla</td>\n",
       "      <td>27.092843</td>\n",
       "      <td>28.878892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>io</td>\n",
       "      <td>37.805838</td>\n",
       "      <td>38.701186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>vanilla</td>\n",
       "      <td>37.629447</td>\n",
       "      <td>38.756979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>128</td>\n",
       "      <td>io</td>\n",
       "      <td>61.262763</td>\n",
       "      <td>62.647250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>128</td>\n",
       "      <td>vanilla</td>\n",
       "      <td>61.089302</td>\n",
       "      <td>62.189090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>256</td>\n",
       "      <td>io</td>\n",
       "      <td>120.672068</td>\n",
       "      <td>124.155692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>256</td>\n",
       "      <td>vanilla</td>\n",
       "      <td>120.531309</td>\n",
       "      <td>123.187750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>512</td>\n",
       "      <td>io</td>\n",
       "      <td>268.554570</td>\n",
       "      <td>272.223254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>512</td>\n",
       "      <td>vanilla</td>\n",
       "      <td>268.906273</td>\n",
       "      <td>273.780362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    seq_len    model  time_avg_ms  time_p95_ms\n",
       "0         8       io    21.845188    31.285430\n",
       "1         8  vanilla    19.478945    25.687145\n",
       "2        16       io    21.550402    22.859014\n",
       "3        16  vanilla    21.397938    21.801143\n",
       "4        32       io    27.146151    28.067425\n",
       "5        32  vanilla    27.092843    28.878892\n",
       "6        64       io    37.805838    38.701186\n",
       "7        64  vanilla    37.629447    38.756979\n",
       "8       128       io    61.262763    62.647250\n",
       "9       128  vanilla    61.089302    62.189090\n",
       "10      256       io   120.672068   124.155692\n",
       "11      256  vanilla   120.531309   123.187750\n",
       "12      512       io   268.554570   272.223254\n",
       "13      512  vanilla   268.906273   273.780362"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(res)\n",
    "\n",
    "df[[\"seq_len\",\"model\",\"time_avg_ms\",\"time_p95_ms\"]].groupby([\"seq_len\",\"model\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "chart_df = pd.merge(df[df.model == 'io'][[\"seq_len\",\"time_p95_ms\"]], df[df.model == 'vanilla'][[\"seq_len\",\"time_p95_ms\"]], on='seq_len')\n",
    "chart_df = chart_df.rename(columns={\"time_p95_ms_x\": \"io_95\", \"time_p95_ms_y\": \"vanilla_p95\"})\n",
    "plt = chart_df.plot(x=\"seq_len\",y=[\"io_95\",\"vanilla_p95\"],kind=\"line\")\n",
    "plt.figure.savefig('cpu_res.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/bin/bash: -c: line 1: syntax error near unexpected token `cpu_res.png'\n",
      "/bin/bash: -c: line 1: `[cpu_res.png](cpu_res.png)'\n"
     ]
    }
   ],
   "source": [
    "![cpu_res.png](cpu_res.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a2c4b191d1ae843dde5cb5f4d1f62fa892f6b79b0f9392a84691e890e33c5a4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
